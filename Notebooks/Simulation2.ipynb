{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "from math import sqrt\n",
    "from statistics import mean\n",
    "from scipy.stats import norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using simulation to investigate Type II error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean1 = 0\n",
    "n = 40\n",
    "effect_size = 0.7\n",
    "sd = 1\n",
    "\n",
    "#n1 = 10000\n",
    "#n2 = 10000\n",
    "\n",
    "group1 = np.random.normal(loc = mean1, scale = sd, size = n)\n",
    "group2 = np.random.normal(loc = mean1 + effect_size * sd, scale = sd, size = n)\n",
    "\n",
    "df = pd.DataFrame({'Group1': group1, 'Group2': group2}).melt(var_name = 'Group', value_name = 'Scores')\n",
    "\n",
    "sns.pointplot(data = df, x = 'Group', y = 'Scores')\n",
    "sns.swarmplot(data = df, x = 'Group', y = 'Scores', hue = 'Group')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.ttest(group1, group2, correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = 0\n",
    "n = 20\n",
    "effect_size = 0.6\n",
    "sd = 1\n",
    "\n",
    "#n1 = 10000\n",
    "#n2 = 10000\n",
    "\n",
    "\n",
    "experiments = 10\n",
    "\n",
    "fig, axes = plt.subplots(1, experiments, figsize=(15, 5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(experiments):\n",
    "   group1 = np.random.normal(loc = mean1, scale = sd, size = n)\n",
    "   group2 = np.random.normal(loc = mean1 + effect_size * sd, scale = sd, size = n)\n",
    "   df = pd.DataFrame({'Group1': group1, 'Group2': group2}).melt(var_name = 'Group', value_name = 'Scores')\n",
    "   sns.pointplot(data = df, x = 'Group', y = 'Scores', ax = axes[i])\n",
    "   sns.swarmplot(data = df, x = 'Group', y = 'Scores', ax = axes[i])\n",
    "   axes[i].set(xlabel=None)\n",
    "   axes[i].set_ylim(-3, 3)\n",
    "   axes[i].axhline(y = mean1, color = 'black', linestyle = 'dotted')\n",
    "   axes[i].axhline(y = effect_size, color = 'orange', linestyle = 'dotted')\n",
    "   sns.despine()\n",
    "   if i > 0:\n",
    "    axes[i].get_yaxis().set_visible(False)\n",
    "   res = pg.ttest(group1,group2)\n",
    "   p = res['p-val'][0]\n",
    "   axes[i].text(0.1, 1, 'p-value: ' + str(round(p,3)), transform=axes[i].transAxes)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sex differences in personality: effect sizes around .2 to .3  \n",
    "- Effects of educational interventions: effect sizes around .3 to .4  \n",
    "- Sex differences in height: effect size around 1.7  \n",
    "\n",
    "(from Dorothy Bishop's [video on effect sizes](https://youtu.be/ovHzFVzJyQg?si=MY4-6MF6Ln2lxyNL&t=247))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "mean1 = 0\n",
    "sd = 1\n",
    "\n",
    "effect_sizes = [0.2, 0.3, 0.4, 0.8, 1, 2]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(effect_sizes), figsize=(15, 5))\n",
    "\n",
    "for i in range(len(effect_sizes)):\n",
    "   group1 = np.random.normal(loc = mean1, scale = sd, size = n)\n",
    "   group2 = np.random.normal(loc = effect_sizes[i] * sd, scale = sd, size = n)\n",
    "   sns.histplot(group1, ax = axes[i])\n",
    "   sns.histplot(group2, ax = axes[i])\n",
    "   sns.despine()\n",
    "   axes[i].text(0.1, 1, 'Effect size: ' + str(effect_sizes[i]), transform=axes[i].transAxes)\n",
    "   if i > 0:\n",
    "      axes[i].get_yaxis().set_visible(False)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using simulation and published research to inform our own research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ethanweed/ExPsyLing/blob/master/Slides/Images/Peel%20et%20al_2022_Figure-3.png?raw=true\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ethanweed/ExPsyLing/blob/master/Slides/Images/Peel%20et%20al%20_2022_Table-1.png?raw=true\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Twenty right-handed, native English speakers (M age = 24.10 years, 7 males) participated in the experiment.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the effect size distribution from Peel et al (2022) comparison between short SOA congruent and incongruent\n",
    " \n",
    "# function to convert standard error to standard deviation\n",
    "# OBS! You may not need to use this function if the article you are working with provides standard deviations instead of standard errors\n",
    "def SE_to_SD (se,n):\n",
    "    sd = se * sqrt(n)\n",
    "    return(sd)\n",
    "\n",
    "# function to sample from a normal distribution\n",
    "# not really necessary, now that I think about it, but maybe it makes the code a little clearer below\n",
    "def take_sample (mean, sd, n):\n",
    "    nums = np.random.normal(loc = mean, scale = sd, size = n)\n",
    "    return(nums)\n",
    "\n",
    "# set the number of participants (from the paper)\n",
    "n = 20\n",
    "\n",
    "# enter the data from Table 1\n",
    "\n",
    "# means\n",
    "mean_Short_Inc = 836\n",
    "mean_Short_Cong = 805\n",
    "mean_Long_Inc = 800\n",
    "mean_Long_Cong = 801\n",
    "\n",
    "\n",
    "# standard errors (convert to standard deviation)\n",
    "sd_Short_Inc = SE_to_SD(27.7, n)\n",
    "sd_Short_Cong = SE_to_SD(28.6, n)\n",
    "sd_Long_Inc = SE_to_SD(27.6, n)\n",
    "sd_Long_Cong = SE_to_SD(28.6, n)\n",
    "\n",
    "# sample from a normal distribution for each combination of mean, standard deviation, and number of participants\n",
    "dist_Short_Inc = take_sample(mean_Short_Inc, sd_Short_Inc, n)\n",
    "dist_Short_Cong = take_sample(mean_Short_Cong, sd_Short_Cong, n)\n",
    "dist_Long_Inc = take_sample(mean_Long_Inc, sd_Long_Inc, n)\n",
    "dist_Long_Cong = take_sample(mean_Long_Cong, sd_Long_Cong, n)\n",
    "\n",
    "# put the results in a dataframe\n",
    "data = pd.DataFrame({'short_inc': dist_Short_Inc,\n",
    "                    'short_cong': dist_Short_Cong,\n",
    "                    'long_inc': dist_Long_Inc,\n",
    "                    'long_cong': dist_Long_Cong})\n",
    "\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pingouin to compute the effect size for the short soa congruent / incongruent comparison\n",
    "pg.compute_effsize(data.short_inc, data.short_cong, paired=True, eftype='cohen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the code from above in a loop, to estimate the distribution of effect sizes based on Peet et al.\n",
    "\n",
    "n = 20\n",
    "\n",
    "effect_sizes = []\n",
    "runs = 1000\n",
    "\n",
    "\n",
    "for i in range(runs):\n",
    "    mean_Short_Inc = 836\n",
    "    mean_Short_Cong = 805\n",
    "    mean_Long_Inc = 800\n",
    "    mean_Long_Cong = 801\n",
    "    \n",
    "    sd_Short_Inc = SE_to_SD(27.7, n)\n",
    "    sd_Short_Cong = SE_to_SD(28.6, n)\n",
    "    sd_Long_Inc = SE_to_SD(27.6, n)\n",
    "    sd_Long_Cong = SE_to_SD(28.6, n)\n",
    "    dist_Short_Inc = take_sample(mean_Short_Inc, sd_Short_Inc, n)\n",
    "    dist_Short_Cong = take_sample(mean_Short_Cong, sd_Short_Cong, n)\n",
    "    dist_Long_Inc = take_sample(mean_Long_Inc, sd_Long_Inc, n)\n",
    "    dist_Long_Cong = take_sample(mean_Long_Cong, sd_Long_Cong, n)\n",
    "\n",
    "    data = pd.DataFrame({'short_inc': dist_Short_Inc,\n",
    "                        'short_cong': dist_Short_Cong,\n",
    "                        'long_inc': dist_Long_Inc,\n",
    "                        'long_cong': dist_Long_Cong})\n",
    "    effect_sizes.append(pg.compute_effsize(data.short_inc, data.short_cong, paired=True, eftype='cohen').round(3))\n",
    "\n",
    "ax = sns.kdeplot(effect_sizes)\n",
    "mean_effect_size = round(np.array(effect_sizes).mean(), 3)\n",
    "ax.axvline(x = mean_effect_size, color = 'black', linestyle = 'dotted')\n",
    "ax.text(0.4, 1.33, 'mean effect size: ' + str(mean_effect_size))\n",
    "sns.despine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ethanweed/ExPsyLing/refs/heads/master/Experiments/Experiment%201/data/data_ExPsyLing_2024.csv')\n",
    "\n",
    "df = df[df['sender'] == 'target']                           # make a dataframe with only the data from the \"target\" rows\n",
    "df = df[df['condition'] != 'practice']                      # make a dataframe that only includes the \"real\" data (not the data from the practice round)\n",
    "\n",
    "df['response_action'] = df['response_action'].replace('keypress(n)', 'n') \n",
    "df['response_action'] = df['response_action'].replace('keypress(m)', 'm')\n",
    "df['correct'] = df['response_action'] == df['correct_response']\n",
    "df = df[df['correct'] == True]\n",
    "df = df[df['duration']< 1400]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.boxplot(data = df[df['soa_condition'] == 'short'], x = 'congruence', y = 'duration')  # make the plot\n",
    "\n",
    "ax = sns.stripplot(data = df[df['soa_condition'] == 'short'], x = 'congruence', y = 'duration', alpha = 0.3)  # make the plot\n",
    "ax = sns.pointplot(data = df[df['soa_condition'] == 'short'], x = 'congruence', y = 'duration', color='black')  # make the plot\n",
    "sns.despine()                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong = df[(df['soa_condition'] == 'short') & (df['congruence'] == 'congruent')]['duration']\n",
    "incong = df[(df['soa_condition'] == 'short') & (df['congruence'] == 'incongruent')]['duration']\n",
    "\n",
    "pg.ttest(cong, incong, paired=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-analysis\n",
    "\n",
    "Estimating effect sizes from the literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/ethanweed/ExPsyLing/blob/master/Slides/Images/Weed%20et%20al_2020_%20RHD%20met-analysis.png?raw=true\" width=\"\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
