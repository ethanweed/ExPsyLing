{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15798cb0-c1eb-435c-b466-7baa01217425",
   "metadata": {},
   "source": [
    "# Variables and variable types\n",
    "\n",
    "## \"Regular\" variables\n",
    "\n",
    "1. strings\n",
    "1. integers\n",
    "1. floats\n",
    "\n",
    "## \"Collection\" variables\n",
    "\n",
    "1. tuples\n",
    "1. lists\n",
    "1. sets\n",
    "1. dictionaries\n",
    "\n",
    "From https://www.w3schools.com:\n",
    "\n",
    "- **List** is a collection which is ordered and changeable. Allows duplicate members.\n",
    "- **Tuple** is a collection which is ordered and unchangeable. Allows duplicate members.\n",
    "- **Set** is a collection which is unordered, \"unchangeable\", and unindexed. No duplicate members.\n",
    "- **Dictionary** is a collection which is ordered and changeable. No duplicate members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f482e1d-4b2c-46b9-b1f8-ba8c84441665",
   "metadata": {},
   "source": [
    "## strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ff8fa-c64e-48f1-97a4-46574e94a090",
   "metadata": {},
   "source": [
    "# Title\n",
    "kksjhdf\n",
    "\n",
    "## smaller\n",
    "sdfdsfsd\n",
    "\n",
    "### even smaller\n",
    "sdfsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44258cb0-cc32-462f-9525-745e24cb4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c99b5c-9d9c-45fd-9726-991e789fd11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b89183-f3df-43a4-925e-14c6d41bfa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11c027c-6c6d-47a5-97ba-4dcb27d08617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = ['cat', 'dog', 'monkey', 'cat', 'dog', 'anteater']\n",
    "type(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c055f4ac-c691-4e96-950b-7f89ae5483f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = ['cat', 'dog', 'monkey', 'cat', 'dog', 'anteater']\n",
    "animals = set(animals)\n",
    "type(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b220ee26-56ab-4b4d-bcb0-82f0d49d59bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anteater', 'cat', 'dog', 'monkey'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0cccdc5-6157-4812-8b9f-9491c32cc6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anteater', 'cat', 'monkey', 'dog']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = list(animals)\n",
    "animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4f44f40-fb20-41f3-b37a-572dd79dbfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a sentence!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'I am a sentence!'\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f1ad46d-3909-4781-a5f1-b646622392c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " ' ',\n",
       " 'a',\n",
       " 'm',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " '!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentlist = list(sent)\n",
    "sentlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13928850-8044-435f-93aa-7ec971af71d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentlist[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc9dde-7c11-4436-a5ec-2c3875413bbc",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e68c879-86d6-4f44-9fe4-5708dd145662",
   "metadata": {},
   "outputs": [],
   "source": [
    " myteacher = {\n",
    "  \"name\": \"Ethan\",\n",
    "  \"subject\": \"Experimental Psycholinguistics\",\n",
    "  \"year_of_birth\": 1973,\n",
    "  \"hair_color\": \"grey\",\n",
    "  \"favorite_fruits\": ['apples', 'grapes', 'oranges']   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7abfd4f9-a0af-4d50-8eeb-16a88dee14ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ethan'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myteacher['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "283992fc-9fbe-4fd7-83e9-e138f8bfbb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apples', 'grapes', 'oranges']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myteacher['favorite_fruits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70f11c88-e7c0-479e-aafb-d8a34c00b806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experimental Psycholinguistics'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myteacher.get('subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27deb5f1-8454-41ec-90f6-7f7ddec5c1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethan\n",
      "Experimental Psycholinguistics\n",
      "grey\n"
     ]
    }
   ],
   "source": [
    "keys = ['name', 'subject', 'hair_color']\n",
    "for key in keys:\n",
    "    print(myteacher.get(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b36e76-9bd3-4041-9657-8bb98bdbc55f",
   "metadata": {},
   "source": [
    "## zipping variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aecbca51-b709-4727-b3b9-b610eac7a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = ['apples', 'grapes', 'oranges']\n",
    "numbers = [4, 8, 32]\n",
    "\n",
    "shopping = zip(fruits, numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d07ee0e8-eef8-47bf-8abd-a90d2e1eb268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apples', 4), ('grapes', 8), ('oranges', 32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(shopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acee81e6-eb9e-4f87-ac7c-e9abd982b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = ['Hamlet', 'King Lear', 'Much Ado About Nothing', 'Macbeth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18b42d4-1952-47d3-b540-84cb55b8cccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Hamlet'),\n",
       " (1, 'King Lear'),\n",
       " (2, 'Much Ado About Nothing'),\n",
       " (3, 'Macbeth')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = list(enumerate(shakespeare))\n",
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d87d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Hamlet', 1: 'King Lear', 2: 'Much Ado About Nothing', 3: 'Macbeth'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict = dict(en)\n",
    "\n",
    "en_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899a593-28bc-4780-b733-aa24c70f80d3",
   "metadata": {},
   "source": [
    "# loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4589c-2675-4b50-a79d-1d4585d7f3fd",
   "metadata": {},
   "source": [
    "### `while` loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f33c3bf9-c75f-4be5-8e09-5c2000554eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "while counter < 10:\n",
    "    counter = counter + 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d5f90-cbdb-4aef-8249-3ed1f0628cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad6264-5c5f-4fd2-9f19-c7eb6418a2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3962f-ed94-4891-935f-30a329685a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb2fca99-dc60-4ccc-bf13-d143a317710d",
   "metadata": {},
   "source": [
    "### `for` loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a21f0222-f0ce-4f60-9bfb-2b16016fb3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet\n",
      "King Lear\n",
      "Much Ado About Nothing\n",
      "Macbeth\n"
     ]
    }
   ],
   "source": [
    "shakespeare = ['Hamlet', 'King Lear', 'Much Ado About Nothing', 'Macbeth']\n",
    "\n",
    "for x in shakespeare:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d38e173-c93d-487b-8186-f1ec33d36e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Macbeth'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f63f92d-dcef-4ce1-8a66-33d4b952f42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Hamlet\n",
      "1 King Lear\n",
      "2 Much Ado About Nothing\n",
      "3 Macbeth\n"
     ]
    }
   ],
   "source": [
    "shakespeare = ['Hamlet', 'King Lear', 'Much Ado About Nothing', 'Macbeth']\n",
    "\n",
    "for index, value in enumerate(shakespeare):\n",
    "    print(index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aebb8484-e680-41fb-b2db-0911ef5812f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linguists = ['Saussure', 'McGregor', 'Sapir', 'Whorf', 'Chomsky', 'Tomasello', 'Bickerton']\n",
    "born = [1857, 1952, 1884, 1897, 1928, 1950, 1926]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60fbebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1857), (1, 1952), (2, 1884), (3, 1897), (4, 1928), (5, 1950), (6, 1926)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(born))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b402e10c-5b03-4a5a-a071-01a814ffe65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saussure\n",
      "Sapir\n",
      "Whorf\n"
     ]
    }
   ],
   "source": [
    "for num, val in enumerate(born):\n",
    "    if val < 1900:\n",
    "        print(linguists[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f31772a-1575-41d6-aab7-18b835546092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saussure 1857\n",
      "Sapir 1884\n",
      "Whorf 1897\n"
     ]
    }
   ],
   "source": [
    "for num, val in enumerate(born):\n",
    "    if val < 1900:\n",
    "        print(linguists[num], val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1608606-2a46-4f79-9f04-9bb073cf5b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguists born in the 19th century: ['Saussure', 'Sapir', 'Whorf']\n",
      "Linguists born in the 20th century: ['McGregor', 'Chomsky', 'Tomasello', 'Bickerton']\n"
     ]
    }
   ],
   "source": [
    "linguists = ['Saussure', 'McGregor', 'Sapir', 'Whorf', 'Chomsky', 'Tomasello', 'Bickerton']\n",
    "born = [1857, 1952, 1884, 1897, 1928, 1950, 1926]\n",
    "\n",
    "before_1900 = []\n",
    "after_1900 = []\n",
    "for num, val in enumerate(born):\n",
    "    if val < 1900:\n",
    "        before_1900.append(linguists[num])\n",
    "    if val >= 1900:\n",
    "        after_1900.append(linguists[num])\n",
    "print('Linguists born in the 19th century:', before_1900)\n",
    "print('Linguists born in the 20th century:', after_1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9375f88e-5a1e-4485-b8d8-911ec19dd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can import pandas to put our data in a spreadsheet format\n",
    "\n",
    "# it is common to rename pandas as \"pd\"\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2d4a49-b670-432a-8d29-ea4674089b64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we can build a \"data frame\" out of a dictionary, where the key is a string, and the value is our list of linguists\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# belonging to each category.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# however, there is a problem, when we try to put our lists into a dataframe:\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df_linguists \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m19th century linguists\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbefore_1900\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m20th century linguists\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter_1900\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m df_linguists\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/p/lib/python3.11/site-packages/pandas/core/frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    730\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    731\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    732\u001b[0m     )\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/p/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/p/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/p/lib/python3.11/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# we can build a \"data frame\" out of a dictionary, where the key is a string, and the value is our list of linguists\n",
    "# belonging to each category.\n",
    "\n",
    "# however, there is a problem, when we try to put our lists into a dataframe:\n",
    "\n",
    "df_linguists = pd.DataFrame({'19th century linguists': before_1900,\n",
    "                            '20th century linguists': after_1900})\n",
    "df_linguists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad40ea6-8b1c-49ff-9503-7f80d06da96e",
   "metadata": {},
   "source": [
    "If we look at the error message, it tells us \"All arrays must be of the same length\". With a little guesswork, we can conclude that  this is because the two lists, `before_1900`, and `after_1900` are different lengths, and `pandas` wants all the columns in its dataframes to be the same length. One way to fix this could be to be to add an empty spot at the end of the shorter list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f03599b8-40ea-42c8-87d2-4abd4a0aabc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# we can use len() to check how long the lists are\n",
    "\n",
    "print(len(before_1900))\n",
    "print(len(after_1900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a405e73-52ac-453f-8bcb-0da2e200dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could just add a space to the end of the short list with \"append()\"\n",
    "\n",
    "before_1900.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c3345a9-fc5e-4a2d-bebb-83eebc456523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19th century linguists</th>\n",
       "      <th>20th century linguists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saussure</td>\n",
       "      <td>McGregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sapir</td>\n",
       "      <td>Chomsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whorf</td>\n",
       "      <td>Tomasello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Bickerton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  19th century linguists 20th century linguists\n",
       "0               Saussure               McGregor\n",
       "1                  Sapir                Chomsky\n",
       "2                  Whorf              Tomasello\n",
       "3                                     Bickerton"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linguists = pd.DataFrame({'19th century linguists': before_1900,\n",
    "                            '20th century linguists': after_1900})\n",
    "df_linguists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69338713-9696-48d7-a0a1-82242ac2e0db",
   "metadata": {},
   "source": [
    "That works fine. Another way would be to find the difference in lengths, and then append that many empty spaces. First, I'll put things back the way they were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eae8ec1-7c77-4aeb-b3bf-0be359d275c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguists born in the 19th century: ['Saussure', 'Sapir', 'Whorf']\n",
      "Linguists born in the 20th century: ['McGregor', 'Chomsky', 'Tomasello', 'Bickerton']\n"
     ]
    }
   ],
   "source": [
    "linguists = ['Saussure', 'McGregor', 'Sapir', 'Whorf', 'Chomsky', 'Tomasello', 'Bickerton']\n",
    "born = [1857, 1952, 1884, 1897, 1928, 1950, 1926]\n",
    "\n",
    "before_1900 = []\n",
    "after_1900 = []\n",
    "for num, val in enumerate(born):\n",
    "    if val < 1900:\n",
    "        before_1900.append(linguists[num])\n",
    "    if val >= 1900:\n",
    "        after_1900.append(linguists[num])\n",
    "print('Linguists born in the 19th century:', before_1900)\n",
    "print('Linguists born in the 20th century:', after_1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb10b27b-4d7d-427e-ac25-0b2578e0e77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Saussure', 'Sapir', 'Whorf', '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = len(after_1900) - len(before_1900)\n",
    "before_1900.append('' * difference)\n",
    "before_1900 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
