{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own concordance\n",
    "\n",
    "In the lecture, we discussed how it took 500 Dominican munks to write the first concordance of the Latin bible, and how it took Rabbi Mordecai Nathan 10 years to write the first concordance of the Hebrew bible. With Python, it only takes a matter of seconds to find words in a text, along with the surrounding words.\n",
    "\n",
    "In this exercise, first run the code and check that everything works. Then, try modifying the code. Do at least to the part where it says **Stop now if you want!** Do as much or as little of the other exercises as you can / want to.\n",
    "\n",
    "Run each cell in this notebook at a time, in order. If something in one cell doesn't work right, it might be because you have overwritten a variable, so try going back and running all the previous cells again.\n",
    "\n",
    "The point of the exercise isn't for you to understand all the commands fully; the idea is to start getting you familiar with how jupyter notebooks work, with the concept of copying and modifying code, and hopefully give you a little taste of the power of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the natural language toolkit package (nltk), which has a copy of several texts, including the King James Bible\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the nltk package so that it is accessible to Python, and download a collection of texts from Project Gutenberg\n",
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called \"bible\" which contains the text of the King James bible.\n",
    "bible = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "bible = bible.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "bible = bible.replace('\\n', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "bible = bible.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a variable called \"concordance\", and fill it with every occurrence of the phrase \"this world\", and a few words preceeding and following \"this world\"\n",
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"world\":\n",
    "        if bible[i-1] == \"this\":\n",
    "            concordance.append(str(' '.join(bible[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at what the algorithm has found\n",
    "concordance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again, but this time let's just search for \"world\" by itself, not \"this world\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"world\":\n",
    "        concordance.append(str(' '.join(bible[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at what the algorithm has found\n",
    "concordance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the cell below, modify the code to search for a different word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your modified code here and run the cell...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nltk package has the full text of several other classic books. You can see what they are called by running the command in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop now if you want!\n",
    "\n",
    "If you have come this far, and got everything to work, you can stop if you want! The goal of this assignment is to successfully run and modify some Python code to achieve a goal. But..... if you want to challenge yourself, here are a few more things you can try. In each case, I have given you a little bit of starter code to get you going.\n",
    "\n",
    "## Challenge 1: build your own concordance\n",
    "\n",
    "Pick a different book and a different word, or pair of words. Copy and paste from the code above to write some Python code that searches the book of your choice for the word or pair of words of your choice. Put this code in the cell below. By the way, some of the texts use the characters \"\\r\" for \"carriage return\" instead of \"\\n\" for \"newline\". You can remove these the same way that you remove the \"\\n\" characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code to search for a word or pair of words in a different book here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: compare lengths of books\n",
    "\n",
    "We can use the command `len` to find how many items there are in a list. E.g., to find the number of words in the list called `bible`, above, we can write: `len(bible)`. \n",
    "\n",
    "Use the starter code below to find out which book in the books included in `nltk` has the most words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution 1: print all the titles and numbers of words\n",
    "# starter code:\n",
    "\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more advanced, for those with some Python experience, or those who want to google around..\n",
    "# solution 2: make a list of titles and a list of wordcounts, zip them together, then sort them based on wordcount\n",
    "# starter code:\n",
    "\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "titles = []\n",
    "numwords = []\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: what are the most frequent words?\n",
    "\n",
    "`nltk` has a built-in function called `FreqDist` which counts up how many times each word in a text occurs. So, if you have a list called `words` which contains all the words in a book, you find the frequencies of all of them by writing `freq = nltk.FreqDist(words)`. You can then get the e.g. ten most common words by writing `freq.most_common(10)`. What are the ten most common words in Jane Austen's \"Emma\"? What about Herman Melville's \"Moby Dick\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code:\n",
    "\n",
    "book = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "words = book.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Remove stopwords\n",
    "\n",
    "Often, the most frequent words are not the most interesting ones. Words like \"a\" and \"the\" are so common in English, that they don't really tell us much about the text. That is why we often remove \"stopwords\", that is, a list of the most common words in English, before e.g. counting frequencies. Below is some starter code to remove stopwords. Use these snippets to see what the most common words in Emma and Moby Dick are after removing these most common words.\n",
    "\n",
    "Hint: In Moby Dick, you will also have to remove the string `\\r`, in addition to removing `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stopwords\n",
    "stopwords = [\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code:\n",
    "\n",
    "book = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "words = book.lower()\n",
    "\n",
    "\n",
    "# code to remove stopwords.\n",
    "words = [word for word in words if word not in stopwords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
