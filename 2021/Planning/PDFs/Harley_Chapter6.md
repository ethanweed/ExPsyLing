# 9781841693408 copy


#### [Page 2](highlights://Harley_Chapter6#page=2)

> Recognising a word means you’ve made a decision in some way that
> the word is familiar; you know that NIGHT is a word and you’ve
> seen it before, and you know that NITE isn’t.

> Identifying a word means that you’ve made some commitment to
> what the word is – sufficiently so to be able to initiate some
> response.

> Understanding a word means that you access the word’s meaning.

> Naming a word is accessing the sound of a word, which in turn
> could mean saying it aloud, or saying it to yourself.

> Psycholinguists have used several tasks to investigate word
> processing, and these tasks relate to these distinctions I’ve
> just made. One of the most popular tasks is the lexical decision
> task;

> You have to press one key if you think the string of letters
> forms a word, and another if you think it’s a non-word. So you
> might see NIGHT or NITE. Researchers measure how long it takes
> the person to make their decision, and also how many errors they
> make.

> In a lexical decision, you don’t have to access the meaning or
> the sound of the word, you just have to say whether it’s
> familiar or not – whether it’s in that set of things you know to
> be words; you might access the sound or meaning, but you don’t
> have to.

> Contrast lexical decision with the naming task, where you see a
> word on the screen and have to say it aloud, and researchers
> measure how long it takes you to start speaking.

#### [Page 3](highlights://Harley_Chapter6#page=3)

> we have to be very careful about what we conclude from lexical
> decision and naming, because these judgements might be
> influenced by meaning.

> the frequency of a word is an extremely important variable in
> word processing – the more common a word is, the easier it is to
> recognise.

> It’s thought that the age at which we are first exposed to a
> word – a variable called age-of-acquisition – is independently
> important, such that we’re faster to process words we learn
> earlier.

> Having seen a word in the recent past makes it easier to
> identify.

> Finally, I must mention semantic priming – we find it easier to
> identify a word if it is preceded by one related in meaning
> (such as DOCTOR and NURSE).

#### [Page 7](highlights://Harley_Chapter6#page=7)

> So suppose you’re sitting in a lovely drawing room watching an
> old lady sewing, and she says the following: Be a dear and pass
> me some thread for my –

> I can only think of a few plausible candidates that could now be
> left in the cohort, “tablecloth”, “tapestry”, “togs”, “tea cosy”
> perhaps, although some of these are less likely than others. If
> the next sound is “a” (as in “tapestry”), I think we’re really
> only left with “tapestry” remaining in the cohort – the context
> pre- cludes the possibility that she might be asking for some
> thread for her tapeworm.

> All spoken words have a point at which they become unique – that
> is, based on perceptual information alone, we can say with
> absolute certainty “this word I’m hearing is tapestry, not
> tapeworm or tabulation”. That point is called the unique- ness
> point.

#### [Page 21](highlights://Harley_Chapter6#page=21)

> The first bold claim

> there is no lexicon in this account. There’s no central
> repository where each word has its own entry and where you
> access that entry to get at a word’s meaning and pronunciation.
> The sounds of words are patterns of activation across the
> phonological units; the meanings are patterns of activation
> across the semantic units; and the print forms are just patterns
> of activation across the ortho- graphic units. We therefore
> can’t decide if something is a word or non-word by looking it up
> in our lexicon, because there is no lexicon; all we can go by is
> what pattern of activation an input string produces across the
> network.

> The second bold claim

> we don’t have separate lexical and non-lexical reading routes
> for pronouncing irregular words and pseudowords respectively;
> instead, the system’s statistical knowledge of all
> spelling–sound correspondences is brought to bear when presented
> with an input string of letters, and in connectionist models all
> knowledge is encoded by the weights of the connections between
> units.

> What happens when the trained model is then given non-words to
> pronounce? Plaut et al. presented the fully trained network with
> over 100 non-words. The net- work gave the “correct” (by which
> we mean the same pronunciation as a human would have given the
> non-word) pronunciation at about the same rate as humans.

> The important conclusion here is that a single route can produce
> human-like pronunciations of regular words, irregular words, and
> pseudowords.

> How can it do this? Because the connections encode the complete
> sum of knowledge about spelling–sound correspondences; it’s a
> super-duper analogy model.


