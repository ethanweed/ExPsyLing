# someTitle

## someAuthor


#### [Page 2](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=2)

> the reader’s (or listener’s) inclination to treat each riddle as
> referring to a separate situation.

> integrated mental representation of the described events.

> Linguistic cues such as definite and indefinite articles can
> either create or reduce ambiguity, and thereby influence com-
> prehension.

#### [Page 3](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=3)

> overar- ching goal of examining how processes of memory and
> language influence general com- prehension.

> discourse genres.

> Comprehenders invoke various types of background knowledge to
> understand described situations. In fact, the use of background
> knowledge is necessary for discourse compre- hension.

> Riddles derive most of their effects from the fact that the
> listener does not know beforehand which violations to expect,
> and what to update in memory. Thus, the acquisition and
> application of background knowledge is an important issue in
> discourse comprehension.

> For the past three decades or so, the consensus view in the
> literature on discourse processing has been that comprehension
> arises out of both information provided by lan- guage experience
> (e.g., linguistic cues in text or speech) and information
> brought to the experience by the reader (e.g., background
> knowledge). However, more important than these separable
> components is the interplay between them, which yields a mental
> repre- sentation of the described situation, termed as mental
> model or situation model (Johnson- Laird, 1983; van Dijk &
> Kintsch, 1983). Considerable work has outlined the contents,
> structure, and construction of situation models. We discuss
> these issues in Section 5.

Situation models: interplay between linguistic and world knowledge

#### [Page 5](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=5)

> he genre of a text can modify readers’ propensities for
> generating inferences, connecting statements across a text, and
> building strong memory for what has been read.

#### [Page 7](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=7)

> the pragmatic functions of first mentions. As examples of the
> importance of first mention, the first sentence of a paragraph
> traditionally conveys the main idea; introductory lectures often
> begin with a preparatory statement on the informa- tion to be
> described (e.g., Mayer, 1984)

> Thus, first-mentioned material receives privileged status during
> comprehension, and sets the stage for the encoding and retrieval
> of subsequent information (e.g., Lorch & Lorch, 1996).

> Lexical and syntactic cues often work in conjunction with each
> other and in conjunction with background knowledge. For example,
> in the sentences “Paul and Markus are going swimming today. I
> hope he has his water wings,” “he” will likely be associated
> with “Paul” given the lack of prior context. The first–mentioned
> concept, in this case Paul, is most likely to fill the anaphor
> slot (Gernsbacher, 1989; Gernsbacher & Hargreaves, 1988). Of
> course, background knowledge can also influence this process.
> If, for example, the reader knew that Markus was a 2-year child
> going to a pool with his father Paul, the reader might be more
> likely to link “he” with “Markus.”

> Thus, the activation of concepts across linguistic inputs is

#### [Page 8](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=8)

> a function of lexical and grammatical cues grammar, contextual
> constraints, and background knowledge (Järvikivi, van Gompel,
> Hyönä, & Bertram, 2005).

> Third graders with background knowledge about soccer out-
> performed seventh graders without this background knowledge in
> recall of a text about soccer

> Given that we may assume that the seventh graders had superior
> reading skills, this result suggests that relevant background
> knowledge can compensate for potential differences in reading
> ability (Recht & Leslie, 1988).

> Knowing that background knowledge affects comprehension is one
> thing, but know- ing how is another. In order to address this
> issue, we need to consider how background knowledge is organized
> in long-term memory (LTM).

#### [Page 9](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=9)

> One popular format of knowledge organization is the semantic
> network (Collins & Quillian, 1969; see also the chapter in this
> volume by Ober and Shenaut), which captures facts in the form of
> nodes in a network and the links between them.

> In proposi- tional notation, this fact can be represented as
> [HAS[GIRAFFE, LONG-NECK]]. If a node in the network is
> activated, for example, because the corresponding word is read,
> it will send activation to its nearest neighbors, which in turn
> will send activation to their nearest neighbors, and so on.
> During each cycle, less activation will be transmitted, such
> that activation gradually dissipates. Thus, LTM is not
> completely activated all of the time. Through this process of
> spreading activation, the network (whether computer or human) is
> able to provide an affirmative response assessing the validity
> of state- ments such as “A giraffe is a mammal.”

> In order to understand discourse, more structured knowledge
> defined by higher-order organizations may be required. For
> example, stories are often set in stereotypical loca- tions
> (e.g., a living room, an office) and involve stereotypical event
> sequences.

#### [Page 10](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=10)

> However, symbolic knowledge structures, even those proposed by
> Schank (1982), are still not flexible enough to explain human
> cognition. Therefore, cognitive scientists have turned their
> attention to neural networks – computer models that are roughly
> based on our understanding of the human nervous system.

> n these neural network models (see also the chapter in this
> volume by Seidenberg and MacDonald), knowledge is not programmed
> by the experimenter, but is acquired by the system as it
> processes input and receives feedback on its performance

> Although connectionist models acquire knowledge structures
> themselves, they require a programmer to provide a stimulus,
> with the model passively receiving it. The model itself has no
> direct way of interacting with the world. A relatively recent
> development in cogni- tive science is to embed neural networks
> in robots that have sensors and effectors and are thus able to
> interact with their environment and learn from these
> interactions (Brooks, 1992; Pfeifer & Scheier, 1999). For
> example, a system has been developed that learns words via
> sensorimotor processes (Roy & Pentland, 2002). As we will
> discuss in Section 7, percep- tual and motor knowledge may play
> an important role in language comprehension.

> A very influential model is Kintsch’s construction–integration
> (CI) model (Kintsch, 1988, 1998),

> According to the CI model, comprehension involves two phases.

> During the construction phase, the verbal input activates
> knowledge in an unconstrained fashion. For example, in the
> sentence “During the earthquake, the mint collapsed,” the word
> “mint” activates both its candy and its building meaning, even
> though only the latter is relevant in the context of the
> sentence.

#### [Page 11](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=11)

> In more recent work, the CI model has been interfaced with a
> latent-semantic analysis (LSA) system, which provides
> information about the as- sociations between words based on the
> similarities of the contexts in which they occur in large
> corpora of texts (Landauer & Dumais, 1997).

> How knowledge is organized is only part of the question. An
> equally important issue is how knowledge is retrieved during
> comprehension.

> However, as our review of knowledge representation shows,
> information is usually thought of as being activated
> automatically, or at least passively

> There are several types of inferences (van den Broek, 1994). For
> example, there are connective (or bridging) and elaborative
> inferences

> Connective inferences provide a way of connecting two successive
> text statements. For example, consider the following two
> sentences: “Murray poured water on the bonfire. The fire went
> out.” The two statements can be integrated by activating the
> knowledge that water extinguishes fire

> Even reader preferences, the wishes and desires readers build
> for story characters and events, influence the construction and
> application of inferences

#### [Page 12](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=12)

> At least partially as a function of this large number of
> potential influences, there is still considerable de- bate about
> the particular circumstances that lead to automatic activation
> of predictive in- ferences.

> the extent to which comprehension involves the active
> construction of a mental representa- tion or a more passive form
> of knowledge activation.

> One extreme view would be that comprehension is a very active
> process, akin to reasoning, in which the comprehender makes a
> conscious effort to generate bridging and elaborative inferences
> in order to arrive at a detailed “high resolution” mental
> representation of the described situation

> At the other extreme is the view that background knowledge is
> retrieved automatically as a function of the processing of
> incoming stimuli; in this the comprehender passively acti- vates
> background knowledge, with integration being a function of such
> passive activa- tion.

> these processes capture two important general intuitions about
> dis- course comprehension.

> The first intuition is that comprehension often seems incom-
> plete, regardless of whether it involves automatic activation or
> strategic processing.

> This suggests that comprehension is a “sloppy” process

> The second intuition is that language comprehension, especially
> narrative comprehension, often produces a sense of experiential
> richness.

#### [Page 13](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=13)

> Students attempt to understand material in line with these
> faulty beliefs, rather than spon- taneously engaging in
> processes of conceptual change to revise their beliefs and
> mental models

> Thus, background knowledge from LTM serves as the scaf- fold for
> newly encountered information, regardless of the validity of
> that knowledge.

> The most basic level is the surface struc- ture, a mental
> representation of the exact text read. Surface representations
> decay rapidly from memory

> The second level, the textbase or propositional representation,
> contains idea units explicitly stated in the text, along with
> some bridging inferences. The textbase represen- tation is also
> described as gist-like memory

> The highest level of representation, often viewed as essential
> to com- prehension, is the situation model

> At this level, readers represent infor- mation described by the
> text, activating knowledge that goes beyond what was explicitly
> stated. Readers often rely on their prior knowledge to fill in
> gaps in the text,

#### [Page 14](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=14)

> Consider the following sentence: “Sid searched for a new
> apartment on the North side of Chicago.

> A surface representation would contain every word in that
> sentence; essentially it would be a verbatim replication of the
> sentence

> A textbase representation would contain the major idea units
> described in the sentence. This would include Sid (as agent)
> searching for an apartment, Sid searching Chicago, and so on.
> Thus, readers at this level would remember the concepts conveyed
> in the sentence (as a sample recall, “Sid was looking for a
> place to live in Northern Chicago”) but not necessarily every
> word

> At the situation level, the reader might build expectations
> about the type of apartment Sid is looking for as a func- tion
> of prior knowledge about Chicago, inferences about the potential
> neighborhoods Sid might be exploring, and perhaps even
> elaborations with respect to why Sid is moving.

> the structure-building framework (Gernsbacher, 1990

#### [Page 15](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=15)

> Space.

#### [Page 16](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=16)

> Time.

#### [Page 17](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=17)

> Entity.

#### [Page 18](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=18)

> Motivation.

#### [Page 19](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=19)

> Causation.

#### [Page 24](highlights://Zwann%20&%20Rapp_Discourse%20Comprehension#page=24)

> He put the wallpaper on the table. Then he put his mug of coffee
> on the wallpaper.

> He put the wallpaper on the wall. Then he put his mug of coffee
> on the wallpaper.


